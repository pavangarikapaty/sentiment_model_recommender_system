# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dpmrIPccWCSt--XEy1g9HWh84mlaUWrU
"""

# Import the required libraries
import pandas as pd, numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords # remove stopwords
from nltk.stem.porter import PorterStemmer #Stemming
from nltk.stem import WordNetLemmatizer # Lemmatization
from collections import Counter
from textblob import TextBlob # spell correction


import nltk
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')

import string # remove punctuation
import re

import sklearn
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression

import warnings
warnings.filterwarnings("ignore")

# import the required libraries
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.feature_selection import RFE

# PCA
from sklearn.decomposition import PCA

from sklearn import metrics
from sklearn.metrics import precision_score, recall_score
from tqdm.notebook import tqdm as log_progress

from sklearn.decomposition import IncrementalPCA

import xgboost as xgb
from sklearn import metrics

# Random Forest
from sklearn.ensemble import RandomForestClassifier

# import library
from imblearn.over_sampling import SMOTE

from datetime import datetime

# Import GridSearchCV
from sklearn import model_selection
# Import the required libraries

from sklearn.model_selection import KFold
from sklearn.model_selection import GridSearchCV
import pickle
from sklearn.model_selection import train_test_split
from sklearn.metrics.pairwise import pairwise_distances

from sklearn.preprocessing import MinMaxScaler
from numpy import *

from flask import Flask, render_template, request

# Load the files
user_prod_final_rating = pd.read_pickle("user_prod_final_rating_df.pkl")
df_prod_reviews_sentiment = pd.read_pickle("df_prod_reviews_sentiment_df.pkl")
rf_pca_tuned_range = pickle.load(open("rf_pca_tuned_range.pkl","rb"))
app = Flask(__name__)

@app.route('/')
def home():
    return render_template("index.html")

@app.route('/predict', methods=["POST"])
def predict():
    if request.method == 'POST':
        message = request.form['message']
        d = user_prod_final_rating.loc[message].sort_values(ascending=False)[0:20]
        
        # Create DataFrame based on recommended Products
        prod_list_df = pd.DataFrame(d)
        prod_list_df.reset_index(inplace=True)
        
        # Filter reviews DataFrame based on the recommended Products selection 
        prod_list = list(prod_list_df["name"])
        
        # filter the df_prod_reviews dataFrame based on list of products recommended
        df_prod_reviews_filter = df_prod_reviews_sentiment[df_prod_reviews_sentiment.name.isin(prod_list)]
        
        # Map X,y from dataframe
        X_filter = df_prod_reviews_filter.drop(columns=["name","reviews_username","reviews_rating","user_sentiment"])
        y_filter = df_prod_reviews_filter[["user_sentiment"]]
        
        # predict churn with Random Forest Model
        y_train_pred_filter = rf_pca_tuned_range.predict(X_filter)
        
        # Create dataframe of predicted values
        y_train_pred_filter_df = pd.DataFrame({'user_sentiment':y_filter["user_sentiment"], 'user_sentiment_Prob':y_train_pred_filter})
        y_train_pred_filter_df['reviewID'] = y_filter["user_sentiment"].index
        
        df_prod_reviews_final= pd.concat([df_prod_reviews_filter[["name","reviews_username","reviews_rating"]],y_train_pred_filter_df],axis=1)
        
        df_prod = df_prod_reviews_final[["name","user_sentiment","user_sentiment_Prob"]]
        
        # Create TP, TN, FP, FN
        df_prod["TP"]=df_prod[(df_prod['user_sentiment'] == 1) & (df_prod['user_sentiment_Prob'] == 1)]["user_sentiment"]
        df_prod["TN"]=df_prod[(df_prod['user_sentiment'] == 0) & (df_prod['user_sentiment_Prob'] == 0)]["user_sentiment"]
        df_prod["FP"]=df_prod[(df_prod['user_sentiment'] == 0) & (df_prod['user_sentiment_Prob'] == 1)]["user_sentiment_Prob"]
        df_prod["FN"]=df_prod[(df_prod['user_sentiment'] == 1) & (df_prod['user_sentiment_Prob'] == 0)]["user_sentiment"]
        
        # group the data 
        df_prod_group = df_prod[["name","FP","FN","TN","TP"]]
        df_prod_reco =df_prod_group.groupby("name").agg(["sum"])
        
        # reset index
        df_prod_reco.reset_index(inplace=True)

        # rename columns
        df_prod_reco.columns=["name","FP","FN","TN","TP"]
        
        #Sensitivity measures how apt the model is to detecting events in the positive class.
        # Measures True Positive Rate
        df_prod_reco["sensitivity"] = round((df_prod_reco["TP"]) / ((df_prod_reco["TP"]) + (df_prod_reco["FN"])),4)
        
        # Specificity measures how exact the assignment to the positive class is
        # Measures True Negative Rate
        df_prod_reco["specificity"] = round((df_prod_reco["TN"]) / ((df_prod_reco["TN"]) + (df_prod_reco["FP"])),4)
        
        # Precision
        df_prod_reco["precision"] = round((df_prod_reco["TP"]) / ((df_prod_reco["TP"]) + (df_prod_reco["FP"])),4)
        
        # Check data
        df_prod_reco.sort_values(by=["sensitivity","precision"],ascending=[False,False],inplace=True)
        
        # Top 5 products
        result = list(df_prod_reco["name"][0:5])
        
        return render_template('result.html',prediction=result)
    
if __name__ == '__main__':
    app.run(debug=True)


